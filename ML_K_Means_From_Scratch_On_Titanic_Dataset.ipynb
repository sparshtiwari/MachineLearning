{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_K-Means_From_Scratch_On_Titanic_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8De3W3lN9TsliZgGeXMix"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldS808z3cQJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e337110-ba12-46cd-d0ef-7591aca35a46"
      },
      "source": [
        "# Implementing K-Means from scratch on the titanic dataset used in the 1st k-means program.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "\n",
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "\n",
        "\n",
        "df = pd.read_excel('/titanic.xls')\n",
        "df.drop(['body','name'], 1, inplace=True)\n",
        "df.fillna(0,inplace=True)\n",
        "\n",
        "def handle_non_numerical_data(df):\n",
        "    \n",
        "    # handling non-numerical data: must convert.\n",
        "    columns = df.columns.values\n",
        "\n",
        "    for column in columns:\n",
        "        text_digit_vals = {}\n",
        "        def convert_to_int(val):\n",
        "            return text_digit_vals[val]\n",
        "\n",
        "        #print(column,df[column].dtype)\n",
        "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
        "            \n",
        "            column_contents = df[column].values.tolist()\n",
        "            #finding just the unique values in the columns\n",
        "            unique_elements = set(column_contents)\n",
        "            # great, found them. \n",
        "            x = 0\n",
        "            for unique in unique_elements:\n",
        "                if unique not in text_digit_vals:\n",
        "                    # creating a dictionary that contains new id per unique string.\n",
        "                    text_digit_vals[unique] = x\n",
        "                    x+=1\n",
        "            # now we map the new \"id\" vlaue\n",
        "            # to replace the string. \n",
        "            df[column] = list(map(convert_to_int,df[column]))\n",
        "\n",
        "    return df\n",
        "\n",
        "df = handle_non_numerical_data(df)\n",
        "\n",
        "# add/remove features just to see how much impact they have.\n",
        "df.drop(['ticket','home.dest'], 1, inplace=True)\n",
        "\n",
        "\n",
        "X = np.array(df.drop(['survived'], 1).astype(float))\n",
        "X = preprocessing.scale(X)\n",
        "y = np.array(df['survived'])\n",
        "\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "correct = 0\n",
        "for i in range(len(X)):\n",
        "\n",
        "    predict_me = np.array(X[i].astype(float))\n",
        "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
        "    prediction = clf.predict(predict_me)\n",
        "    if prediction == y[i]:\n",
        "        correct += 1\n",
        "\n",
        "\n",
        "print(correct/len(X))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7074102368220015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZI6JbQHk2Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Voila ! even from scratch we are able to replicate the accuracy which we got from  sklearn's k-means algo means we did alright."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}